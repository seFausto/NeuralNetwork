import java.util.ArrayList;
import java.util.Random;

public class Neuron {

	private double _outputValue;
	private int _myIndex;
	private ArrayList<Connection> _outputWeights;
	public double _gradient = 0;

	public Neuron(int numberOfOutputs, int myIndex) {
		Random r = new Random();
		_myIndex = myIndex;
		_outputWeights = new ArrayList<Connection>();

		for (int i = 0; i < numberOfOutputs; i++) {
			Connection c = new Connection();
			c.weight = r.nextDouble();

			_outputWeights.add(new Connection());

		}
	}

	public void SetOutputValue(double outputValue) {
		_outputValue = outputValue;
	}

	public double GetOuputValue() {
		return _outputValue;
	}

	public void FeedForward(Layer previousLayer) {
		double sum = 0f;

		for (int n = 0; n < previousLayer.Neurons.size(); n++) {
			sum += previousLayer.Neurons.get(n).GetOuputValue()
					* previousLayer.Neurons.get(n)._outputWeights.get(_myIndex).weight;
		}

		_outputValue = Activation(sum);
	}

	public double Activation(double sum) {
		// convert to sigmoid
		return Math.tanh(sum);
	}

	public void CalcOuputGradients(double targetValue) {
		double delta = targetValue - _outputValue;
		_gradient = delta * ActivationDerivative(_outputValue);

	}

	public void CalcHiddenGradients(Layer nextLayer)
	{
		double dow = SumDow(nextLayer);
		_gradient = dow * ActivationDerivative(_outputValue); 
		
		
	}
	
	
	public void UpdateInputWeights(Layer previousLayer)
	{
		for (int i = 0; i < previousLayer.Neurons.size(); i++) {
			Neuron neuron = previousLayer.Neurons.get(i);
					
				
		}
		
		
	}
	
	private double SumDow(Layer nextLayer) {
		double sum = 0d;
		
		for (int i = 0; i < nextLayer.size() -1; i++) {
			sum += _outputWeights.get(i).weight * nextLayer.Neurons.get(i)._gradient;
				
		}
		return 0;
	}

	private double ActivationDerivative(double sum) {
		// convert to sigmoid
		return 1.0 - sum * sum;
	}
}
